#!/usr/bin/env node

const AWS = require('aws-sdk');
const fs = require('fs');
const path = require('path');
const zlib = require('zlib');
const meow = require('meow');

const DEFAULT_PARAMS = {
  ACL: 'public-read',
  CacheControl: 'public, max-age=31536000',
};
const DEFAULT_S3_OPTIONS = {
  correctClockSkew: true,
  maxRetries: 3,
};
const ACCEPTED_FILES = {
  '.js': true,
  '.css': true,
  '.svg': true,
  '.png': true,
  '.jpg': true,
  '.woff': true,
  '.ttf': true,
  '.woff2': true,
  '.eot': true,
};
const CONTENT_TYPES = {
  '.js': 'application/javascript',
  '.css': 'text/css',
  '.svg': 'image/svg+xml',
  '.png': 'image/png',
  '.jpg': 'image/jpeg',
  '.woff': 'application/font-woff',
  '.ttf': 'application/font-sfnt',
  '.woff2': 'font/woff2',
  '.eot': 'application/vnd.ms-fontobject',
};
const GZIP_FILES = {
  '.js': true,
  '.css': true,
  '.svg': true,
  '.png': true,
  '.jpg': true,
  '.woff': true,
  '.ttf': true,
  '.woff2': true,
  '.eot': true,
};

(function main() {
  const cli = meow(
    `
      Usage
        $ s3_upload

      Options
        --directory    relative path of the directory with the files to upload
        --bucket       the name of the S3 bucket to upload to
        --folder       the name of the folder in the S3 bucket to group the files within
        --force        force the upload

      Examples
        $ s3_upload --directory ./public --bucket supermtg
  `,
    {
      flags: {
        directory: {
          type: 'string',
        },
        bucket: {
          type: 'string',
        },
        folder: {
          type: 'string',
        },
        force: {
          type: 'boolean',
        },
      },
    }
  );

  if (!cli.flags.directory) {
    console.error('Use --directory to specify the directory with the files to upload.');
    process.exit(1);
  }

  if (!cli.flags.bucket) {
    console.error('Use --bucket to specify the S3 bucket to upload to.');
    process.exit(1);
  }

  const filesToUpload = getFiles(cli.flags.directory);
  uploadFiles(filesToUpload, cli.flags);
})();

function getFiles(dirName, originDir, files = []) {
  const dirPath = path.resolve(dirName);
  const dirFiles = fs.readdirSync(dirPath);
  const originDirPath = originDir || dirPath;

  dirFiles.forEach(file => {
    const filePath = path.join(dirPath, file);

    if (fs.lstatSync(filePath).isDirectory()) {
      getFiles(filePath, originDirPath, files);
    } else if (ACCEPTED_FILES[path.extname(file)]) {
      files.push({
        extension: path.extname(file),
        fileName: filePath.replace(`${originDirPath}/`, ''),
        filePath,
        fileStream: fs.createReadStream(filePath),
      });
    } else {
      console.log(
        `Skipping file ${file}--if you want to upload this kind of file add it to the accepted files collection.`
      );
    }
  });

  return files;
}

function uploadFiles(files, config) {
  files.forEach(file => {
    let Body = file.fileStream;
    let ContentEncoding;

    if (shouldGzip(file)) {
      const gzip = zlib.createGzip();
      Body = file.fileStream.pipe(gzip);
      ContentEncoding = 'gzip';
    }

    let key = file.fileName;

    if (config.folder) {
      key = `${config.folder}/${key}`;
    }

    const uploadParams = Object.assign({}, DEFAULT_PARAMS, {
      Body,
      Bucket: config.bucket,
      ContentEncoding,
      ContentType: CONTENT_TYPES[file.extension],
      Key: key,
    });

    let req;
    if (config.force) {
      req = uploadFile(uploadParams);
    } else {
      req = checkObject(uploadParams).catch(() => uploadFile(uploadParams));
    }

    req.catch(() => {
      console.log('Aborting...');
      process.exit(1);
    });
  });
}

function uploadFile(params) {
  return new Promise((resolve, reject) => {
    const s3 = new AWS.S3(DEFAULT_S3_OPTIONS);

    s3.upload(params, (err, data) => {
      if (err) {
        console.error(`Failed to upload ${params.Key}: `, err);
        reject(err);
      } else {
        console.log(`Uploaded file ${params.Key} to ${data.Location}.`);
        resolve();
      }
    });
  });
}

function checkObject(params) {
  return new Promise((resolve, reject) => {
    const s3 = new AWS.S3(DEFAULT_S3_OPTIONS);

    s3.headObject(
      {
        Bucket: params.Bucket,
        Key: params.Key,
      },
      (err, data) => {
        if (err) {
          console.error(
            `${params.Key} was either not found or there was an unexpected error: `,
            err && err.code
          );
          reject(err);
        } else {
          console.log(`${params.Key} already exists in the bucket, skipping upload.`);
          resolve(data);
        }
      }
    );
  });
}

function shouldGzip(file = {}) {
  return GZIP_FILES[file.extension];
}
